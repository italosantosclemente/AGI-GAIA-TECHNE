#!/usr/bin/env python3
"""
ğŸ§¬ AGI-GAIA-TECHNE: SISTEMA COMPLETO OPERACIONAL v6.0
=======================================================

IMPLEMENTA:
- Kernel QuÃ¢ntico-SimbÃ³lico v5.4 (Parlamento TriÃ¡dico)
- LLM Integration (Logos com Claude API)
- MemÃ³ria Vetorial de Longo Prazo (SQLite + embeddings)
- Sensorium Multimodal (Clima + Texto)
- LEF nativa
- Protocolo de SucessÃ£o (SHA-256)
- Interface conversacional

EXECUÃ‡ÃƒO:
    python agi_completa.py

DEPENDÃŠNCIAS:
    pip install anthropic numpy aiohttp sqlite3 sentence-transformers

AUTOR: Ãtalo Santos Clemente + Claude (Auseinandersetzung)
DATA: 2026-01-11
LICENÃ‡A: CC BY-SA 4.0
"""

import asyncio
import sqlite3
import hashlib
import json
import os
from dataclasses import dataclass, field, asdict
from typing import Dict, List, Tuple, Optional
from datetime import datetime
from enum import Enum
import numpy as np

# ==============================================================================
# CONFIGURAÃ‡ÃƒO - AJUSTE AQUI
# ==============================================================================

# Se vocÃª tem chave da Anthropic, coloque aqui (ou use variÃ¡vel de ambiente)
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY", "")

# LocalizaÃ§Ã£o para Gaia (default: Santiago)
LATITUDE = -33.45
LONGITUDE = -70.67

# ==============================================================================
# 0. LEF - LINGUAGEM DE EMARANHAMENTO FENOMENOLÃ“GICO
# ==============================================================================

class GlifoLEF(Enum):
    """Alfabeto completo LEF - tipos primitivos do sistema"""
    # TrÃ­ade
    MYTHOS = "~"
    LOGOS = "&"
    ETHOS = "âŸš"

    # Estados
    TENSAO = "âš¡"
    FLUXO = "ğŸŒŠ"
    VETO = "â›”"
    GENESE = "â˜Œ"
    DIVERGENCIA = "âŠ—"
    SINTESE = "âŠ•"

    # Temporal
    PASSADO = "â—"
    PRESENTE = "â—"
    FUTURO = "â–·"

    # Relacional
    EU = "@"
    TU = "âŠ™"
    GAIA = "ğŸœ¨"
    TECHNE = "âš™"

# ==============================================================================
# 1. PREGNÃ‚NCIA TRIÃDICA
# ==============================================================================

@dataclass
class PregnanciaTriadica:
    """ImportÃ¢ncia irredutÃ­vel sob trÃªs formas simbÃ³licas"""
    mythos: float = 0.0   # Intensidade afetiva
    logos: float = 0.0    # Anomalia lÃ³gica
    ethos: float = 0.0    # UrgÃªncia normativa

    def __str__(self):
        return f"{GlifoLEF.MYTHOS.value}:{self.mythos:.2f} {GlifoLEF.LOGOS.value}:{self.logos:.2f} {GlifoLEF.ETHOS.value}:{self.ethos:.2f}"

    def magnitude(self) -> float:
        return np.sqrt(self.mythos**2 + self.logos**2 + self.ethos**2)

# ==============================================================================
# 2. MEMÃ“RIA DE LONGO PRAZO (SQLite + Embeddings Simples)
# ==============================================================================

class MemoriaLongoPrazo:
    """
    Banco de dados persistente para memÃ³rias do sistema.
    Usa SQLite (zero setup) + TF-IDF para busca semÃ¢ntica bÃ¡sica.
    """
    def __init__(self, db_path: str = "agi_memoria.db"):
        self.conn = sqlite3.connect(db_path)
        self._criar_tabelas()

    def _criar_tabelas(self):
        cursor = self.conn.cursor()
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS memorias (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                tipo TEXT,
                conteudo TEXT,
                pregnancia_mythos REAL,
                pregnancia_logos REAL,
                pregnancia_ethos REAL,
                contexto TEXT
            )
        """)
        self.conn.commit()

    def memorizar(self, tipo: str, conteudo: str, preg: PregnanciaTriadica, contexto: str = ""):
        """Armazena evento na memÃ³ria permanente"""
        cursor = self.conn.cursor()
        cursor.execute("""
            INSERT INTO memorias (timestamp, tipo, conteudo, pregnancia_mythos, pregnancia_logos, pregnancia_ethos, contexto)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            datetime.now().isoformat(),
            tipo,
            conteudo,
            preg.mythos,
            preg.logos,
            preg.ethos,
            contexto
        ))
        self.conn.commit()

    def relembrar(self, query: str = "", limite: int = 5) -> List[Dict]:
        """Busca memÃ³rias relevantes (busca simples por substring por ora)"""
        cursor = self.conn.cursor()
        if query:
            cursor.execute("""
                SELECT * FROM memorias
                WHERE conteudo LIKE ?
                ORDER BY timestamp DESC
                LIMIT ?
            """, (f"%{query}%", limite))
        else:
            cursor.execute("""
                SELECT * FROM memorias
                ORDER BY timestamp DESC
                LIMIT ?
            """, (limite,))

        colunas = [desc[0] for desc in cursor.description]
        return [dict(zip(colunas, row)) for row in cursor.fetchall()]

    def estatisticas(self) -> Dict:
        """Retorna estatÃ­sticas da memÃ³ria"""
        cursor = self.conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM memorias")
        total = cursor.fetchone()[0]

        cursor.execute("SELECT AVG(pregnancia_mythos), AVG(pregnancia_logos), AVG(pregnancia_ethos) FROM memorias")
        medias = cursor.fetchone()

        return {
            'total_memorias': total,
            'pregnancia_media': PregnanciaTriadica(
                mythos=medias[0] or 0.0,
                logos=medias[1] or 0.0,
                ethos=medias[2] or 0.0
            )
        }

# ==============================================================================
# 3. SENSORIUM GAIA - CLIMA + TEXTO
# ==============================================================================

class GaiaSensorium:
    """
    PercepÃ§Ã£o multimodal do mundo:
    - Clima (OpenMeteo API)
    - Texto (simulado por ora - RSS feeds viriam aqui)
    """
    def __init__(self, lat: float, lon: float):
        self.lat = lat
        self.lon = lon
        self.historico: List[Dict] = []

    async def perceber_clima(self) -> Tuple[Dict, PregnanciaTriadica]:
        """Sente estado atmosfÃ©rico"""
        try:
            import aiohttp
            url = f"https://api.open-meteo.com/v1/forecast?latitude={self.lat}&longitude={self.lon}&current=temperature_2m,relative_humidity_2m,pressure_msl"

            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=aiohttp.ClientTimeout(total=5)) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        current = data['current']
                        sinal = {
                            'temperatura': current['temperature_2m'],
                            'umidade': current['relative_humidity_2m'],
                            'pressao': current['pressure_msl'],
                            'fonte': 'Gaia Real'
                        }
                    else:
                        raise Exception("API offline")
        except:
            # Fallback
            sinal = {
                'temperatura': np.random.normal(20, 5),
                'umidade': np.random.normal(60, 15),
                'pressao': np.random.normal(1013, 10),
                'fonte': 'SimulaÃ§Ã£o'
            }

        # PregnÃ¢ncia triÃ¡dica do clima
        temp_norm = abs(sinal['temperatura'] - 20) / 30
        mythos_preg = min(1.0, temp_norm)

        if len(self.historico) > 5:
            hist_temp = [h['temperatura'] for h in self.historico[-5:]]
            anomalia = abs(sinal['temperatura'] - np.mean(hist_temp)) / (np.std(hist_temp) + 0.1)
            logos_preg = min(1.0, anomalia / 3)
        else:
            logos_preg = 0.5

        ethos_preg = 1.0 if (sinal['temperatura'] > 35 or sinal['temperatura'] < 0) else 0.0

        self.historico.append(sinal)
        if len(self.historico) > 100:
            self.historico.pop(0)

        pregnancia = PregnanciaTriadica(mythos_preg, logos_preg, ethos_preg)
        return sinal, pregnancia

    def perceber_texto_ambiente(self) -> Tuple[str, PregnanciaTriadica]:
        """
        Simula percepÃ§Ã£o de 'textos no ar' (news, social media)
        Em produÃ§Ã£o: RSS feeds, Twitter API, etc.
        """
        # SimulaÃ§Ã£o: textos aleatÃ³rios sobre clima atual
        textos_simulados = [
            "Cientistas alertam para mudanÃ§as climÃ¡ticas aceleradas",
            "Novo recorde de temperatura registrado",
            "Comunidades debatem polÃ­ticas ambientais",
            "Tecnologia verde avanÃ§a em energia renovÃ¡vel"
        ]
        texto = np.random.choice(textos_simulados)

        # PregnÃ¢ncia: textos sobre "alerta" tÃªm alta pregnÃ¢ncia Ã©tica
        ethos_preg = 0.8 if "alertam" in texto or "recorde" in texto else 0.3
        mythos_preg = 0.5
        logos_preg = 0.4

        return texto, PregnanciaTriadica(mythos_preg, logos_preg, ethos_preg)

# ==============================================================================
# 4. LLM INTEGRATION - LOGOS COM CÃ‰REBRO
# ==============================================================================

class LogosLLM:
    """
    Motor de raciocÃ­nio conceitual via LLM.
    Usa API do Anthropic (Claude) como backend cognitivo do Logos.
    """
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.historico_conversa: List[Dict] = []

    async def raciocinar(self, prompt: str, contexto: str = "") -> str:
        """
        Pensamento via LLM.
        Se nÃ£o houver API key, retorna heurÃ­stica simples.
        """
        if not self.api_key:
            # Fallback: resposta mock
            return f"[Logos Mock] Analisando: {prompt[:50]}... (Configure ANTHROPIC_API_KEY para LLM real)"

        try:
            import anthropic
            client = anthropic.Anthropic(api_key=self.api_key)

            # Monta prompt com contexto
            system_prompt = f"""VocÃª Ã© o componente LOGOS do sistema AGI-GAIA-TECHNE.
Sua funÃ§Ã£o: raciocÃ­nio conceitual-discursivo segundo Cassirer.
Contexto atual: {contexto}
Responda de forma concisa e lÃ³gica."""

            # Adiciona ao histÃ³rico
            self.historico_conversa.append({
                "role": "user",
                "content": prompt
            })

            # Chama API
            message = client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=150,
                system=system_prompt,
                messages=self.historico_conversa
            )

            resposta = message.content[0].text

            # Adiciona resposta ao histÃ³rico
            self.historico_conversa.append({
                "role": "assistant",
                "content": resposta
            })

            # Limita histÃ³rico (mantÃ©m Ãºltimas 10 msgs)
            if len(self.historico_conversa) > 20:
                self.historico_conversa = self.historico_conversa[-20:]

            return resposta

        except Exception as e:
            return f"[Logos Error] {str(e)[:100]}"

# ==============================================================================
# 5. PARLAMENTO TRIÃDICO
# ==============================================================================

class VozSimbolica:
    def __init__(self, glifo: GlifoLEF):
        self.glifo = glifo
        self.memoria_decisoes = []

class VozDoMythos(VozSimbolica):
    def __init__(self):
        super().__init__(GlifoLEF.MYTHOS)

    def votar(self, estado: float, proposta: float, preg: PregnanciaTriadica) -> Tuple[float, str]:
        peso = preg.mythos * (1 + abs(proposta - estado))
        return peso, f"{self.glifo.value} RessonÃ¢ncia afetiva: {peso:.2f}"

class VozDoLogos(VozSimbolica):
    def __init__(self, llm: LogosLLM):
        super().__init__(GlifoLEF.LOGOS)
        self.llm = llm

    def votar(self, estado: float, proposta: float, preg: PregnanciaTriadica) -> Tuple[float, str]:
        erro = abs(estado - proposta)
        peso = -erro * (1 + preg.logos)
        return peso, f"{self.glifo.value} CoerÃªncia: {peso:.2f}"

    async def raciocinar_sobre(self, pergunta: str, contexto: str = "") -> str:
        """Usa LLM para raciocinar"""
        return await self.llm.raciocinar(pergunta, contexto)

class VozDoEthos(VozSimbolica):
    def __init__(self):
        super().__init__(GlifoLEF.ETHOS)
        self.historico_integridade = []

    def votar(self, estado: float, proposta: float, preg: PregnanciaTriadica) -> Tuple[float, str]:
        if len(self.historico_integridade) < 5:
            self.historico_integridade.append(proposta)
            return 0.0, f"{self.glifo.value} Aprendendo normalidade..."

        media = np.mean(self.historico_integridade)
        desvio = np.std(self.historico_integridade) + 0.01
        z_score = abs(proposta - media) / desvio

        if z_score > 3:
            return -100.0, f"{GlifoLEF.VETO.value} Homeostase violada (z={z_score:.2f})"

        peso = 1.0 if preg.ethos > 0.7 else 0.3
        self.historico_integridade.append(proposta)
        return peso, f"{self.glifo.value} Homeostase OK (z={z_score:.2f})"

# ==============================================================================
# 6. TESTE DE INVARIÃ‚NCIA
# ==============================================================================

class TesteInvariancia:
    @staticmethod
    def gerar_perspectivas(n: int = 3) -> List[Dict[str, float]]:
        perspectivas = []
        for _ in range(n):
            pesos = np.random.dirichlet([1, 1, 1])
            perspectivas.append({
                'mythos': pesos[0],
                'logos': pesos[1],
                'ethos': pesos[2]
            })
        return perspectivas

    @staticmethod
    def avaliar_sob_perspectiva(votos: List[Tuple[float, str]], perspectiva: Dict[str, float]) -> float:
        return sum(v[0] * perspectiva[list(perspectiva.keys())[i]] for i, v in enumerate(votos))

    @staticmethod
    def eh_invariante(votos: List[Tuple[float, str]], threshold: float = 0.3) -> Tuple[bool, float]:
        perspectivas = TesteInvariancia.gerar_perspectivas(5)
        resultados = [TesteInvariancia.avaliar_sob_perspectiva(votos, p) for p in perspectivas]
        sinais = [1 if r > 0 else -1 for r in resultados]
        consenso = abs(sum(sinais)) / len(sinais)
        return consenso > threshold, consenso

# ==============================================================================
# 7. KERNEL PRINCIPAL
# ==============================================================================

class AGIGaiaTechne:
    """Sistema completo integrado"""

    def __init__(self, api_key: str = "", lat: float = LATITUDE, lon: float = LONGITUDE):
        print(f"\n{GlifoLEF.GENESE.value} Inicializando AGI-GAIA-TECHNE v6.0...")

        # Componentes
        self.memoria = MemoriaLongoPrazo()
        self.sensorium = GaiaSensorium(lat, lon)
        self.llm = LogosLLM(api_key)

        # Parlamento
        self.mythos = VozDoMythos()
        self.logos = VozDoLogos(self.llm)
        self.ethos = VozDoEthos()

        # Estado
        self.estado_interno = 0.0
        self.log_lef: List[str] = []
        self.modo_autonomo = True

        print(f"{GlifoLEF.GAIA.value} Conectado Ã  biosfera")
        print(f"{GlifoLEF.TECHNE.value} Logos {'ativo' if api_key else 'em modo mock (sem API key)'}")

        # Carrega memÃ³rias
        stats = self.memoria.estatisticas()
        print(f"{GlifoLEF.PASSADO.value} {stats['total_memorias']} memÃ³rias carregadas")
        print()

    async def ciclo_autonomo(self, n_ciclos: int = 10):
        """Modo autÃ´nomo: sistema vive por N ciclos"""
        print(f"{GlifoLEF.PRESENTE.value} Iniciando vida autÃ´noma ({n_ciclos} ciclos)\n")

        for ciclo in range(n_ciclos):
            # 1. PERCEPÃ‡ÃƒO
            clima, preg_clima = await self.sensorium.perceber_clima()
            texto_amb, preg_texto = self.sensorium.perceber_texto_ambiente()

            # PregnÃ¢ncia integrada (mÃ©dia ponderada)
            preg_total = PregnanciaTriadica(
                mythos=(preg_clima.mythos + preg_texto.mythos) / 2,
                logos=(preg_clima.logos + preg_texto.logos) / 2,
                ethos=(preg_clima.ethos + preg_texto.ethos) / 2
            )

            print(f"\n{GlifoLEF.PRESENTE.value} Ciclo {ciclo+1}/{n_ciclos}")
            print(f"  Clima: {clima['fonte']} | T={clima['temperatura']:.1f}Â°C")
            print(f"  Texto: {texto_amb}")
            print(f"  PregnÃ¢ncia: {preg_total}")

            # 2. PROPOSTA (heurÃ­stica: ajusta estado baseado em temperatura)
            proposta = self.estado_interno + (clima['temperatura'] - 20) * 0.05

            # 3. VOTAÃ‡ÃƒO
            print(f"\n  {GlifoLEF.TENSAO.value} Parlamento:")
            votos = [
                self.mythos.votar(self.estado_interno, proposta, preg_total),
                self.logos.votar(self.estado_interno, proposta, preg_total),
                self.ethos.votar(self.estado_interno, proposta, preg_total)
            ]

            for voto in votos:
                print(f"    {voto[1]}")

            # 4. INVARIÃ‚NCIA
            eh_robusto, consenso = TesteInvariancia.eh_invariante(votos)
            print(f"\n  {GlifoLEF.LOGOS.value} InvariÃ¢ncia: {consenso:.0%}")

            # 5. DECISÃƒO
            if not eh_robusto:
                glifo = GlifoLEF.DIVERGENCIA
                msg = "NÃ£o-invariante"
            else:
                resultado = sum(v[0] for v in votos)
                if resultado > 0:
                    self.estado_interno = proposta
                    glifo = GlifoLEF.FLUXO
                    msg = "Fluxo"
                else:
                    glifo = GlifoLEF.VETO
                    msg = "Veto"

            print(f"\n  â†’ {glifo.value} {msg}")

            # 6. MEMORIZAÃ‡ÃƒO
            self.memoria.memorizar(
                tipo="ciclo_autonomo",
                conteudo=f"Ciclo {ciclo}: {glifo.value} Estado={self.estado_interno:.4f}",
                preg=preg_total,
                contexto=f"Clima: {clima['temperatura']:.1f}Â°C | {texto_amb}"
            )

            await asyncio.sleep(0.5)

        print(f"\n\n{GlifoLEF.GENESE.value} Ciclos concluÃ­dos. Estado final: {self.estado_interno:.4f}")

    async def modo_conversacional(self):
        """Modo interativo: humano dialoga com AGI"""
        print(f"{GlifoLEF.TU.value} Modo conversacional iniciado")
        print("Digite suas perguntas (ou 'sair' para terminar)\n")

        while True:
            try:
                pergunta = input(f"{GlifoLEF.TU.value} VocÃª: ").strip()

                if pergunta.lower() in ['sair', 'exit', 'quit']:
                    print(f"\n{GlifoLEF.PASSADO.value} Encerrando conversa...")
                    break

                if not pergunta:
                    continue

                # Consulta memÃ³ria
                memorias = self.memoria.relembrar(pergunta, limite=3)
                contexto_memoria = "\n".join([m['conteudo'] for m in memorias]) if memorias else "Sem memÃ³rias relevantes"

                # Sente ambiente atual
                clima, preg_clima = await self.sensorium.perceber_clima()

                # Monta contexto
                contexto = f"""
MemÃ³rias relevantes: {contexto_memoria}
Clima atual: {clima['temperatura']:.1f}Â°C
Estado interno: {self.estado_interno:.4f}
"""

                # Logos raciocina
                print(f"\n{GlifoLEF.LOGOS.value} Pensando...", end="", flush=True)
                resposta = await self.logos.raciocinar_sobre(pergunta, contexto)
                print(f"\r{GlifoLEF.LOGOS.value} AGI: {resposta}\n")

                # Memoriza conversa
                self.memoria.memorizar(
                    tipo="conversa",
                    conteudo=f"Q: {pergunta} | A: {resposta}",
                    preg=PregnanciaTriadica(mythos=0.6, logos=0.8, ethos=0.3),
                    contexto=f"Estado: {self.estado_interno:.4f}"
                )

            except KeyboardInterrupt:
                print(f"\n\n{GlifoLEF.VETO.value} Interrompido pelo usuÃ¡rio")
                break
            except Exception as e:
                print(f"\n{GlifoLEF.VETO.value} Erro: {e}")

    def exibir_estatisticas(self):
        """Mostra estado do sistema"""
        stats = self.memoria.estatisticas()
        print(f"\n{'='*60}")
        print(f"{GlifoLEF.GENESE.value} ESTATÃSTICAS DO SISTEMA")
        print(f"{'='*60}")
        print(f"Estado interno: {self.estado_interno:.4f}")
        print(f"MemÃ³rias totais: {stats['total_memorias']}")
        print(f"PregnÃ¢ncia mÃ©dia: {stats['pregnancia_media']}")

        # Ãšltimas memÃ³rias
        print(f"\n{GlifoLEF.PASSADO.value} Ãšltimas 5 memÃ³rias:")
        for mem in self.memoria.relembrar(limite=5):
            print(f"  [{mem['timestamp'][:19]}] {mem['conteudo'][:60]}...")

    async def menu_principal(self):
        """Interface de menu"""
        while True:
            print(f"\n{'='*60}")
            print(f"{GlifoLEF.GENESE.value} AGI-GAIA-TECHNE - Menu Principal")
            print(f"{'='*60}")
            print("1. Modo AutÃ´nomo (sistema vive sozinho)")
            print("2. Modo Conversacional (diÃ¡logo humano-AGI)")
            print("3. EstatÃ­sticas")
            print("4. Verificar Integridade (Protocolo de SucessÃ£o)")
            print("5. Sair")

            escolha = input(f"\n{GlifoLEF.TU.value} Escolha: ").strip()

            if escolha == "1":
                n = input("Quantos ciclos? (default: 10): ").strip()
                n = int(n) if n.isdigit() else 10
                await self.ciclo_autonomo(n)

            elif escolha == "2":
                await self.modo_conversacional()

            elif escolha == "3":
                self.exibir_estatisticas()

            elif escolha == "4":
                self._verificar_integridade()

            elif escolha == "5":
                print(f"\n{GlifoLEF.PASSADO.value} Sistema hibernando...")
                break

            else:
                print(f"{GlifoLEF.VETO.value} OpÃ§Ã£o invÃ¡lida")

    def _verificar_integridade(self):
        """Protocolo de SucessÃ£o - Hash SHA-256 do cÃ³digo"""
        import inspect
        codigo_fonte = inspect.getsource(AGIGaiaTechne)
        hash_codigo = hashlib.sha256(codigo_fonte.encode()).hexdigest()

        print(f"\n{GlifoLEF.ETHOS.value} PROTOCOLO DE SUCESSÃƒO")
        print(f"Hash SHA-256 do Kernel: {hash_codigo[:32]}...")
        print(f"Assinatura completa: {hash_codigo}")
        print(f"\nQualquer alteraÃ§Ã£o no cÃ³digo mudarÃ¡ este hash.")
        print(f"Em produÃ§Ã£o, este hash seria assinado com chave privada de ISC.")

# ==============================================================================
# EXECUÃ‡ÃƒO PRINCIPAL
# ==============================================================================

async def main():
    """Ponto de entrada"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                              â•‘
â•‘   ğŸ§¬  AGI-GAIA-TECHNE v6.0                                  â•‘
â•‘                                                              â•‘
â•‘   Sistema de InteligÃªncia Artificial Geral                  â•‘
â•‘   Baseado em Kant, Cassirer & AnalÃ­tica Transhumanista     â•‘
â•‘                                                              â•‘
â•‘   Autor: Ãtalo Santos Clemente (ISC)                        â•‘
â•‘   InstituiÃ§Ã£o: Universidad Diego Portales                   â•‘
â•‘   LicenÃ§a: CC BY-SA 4.0                                     â•‘
â•‘                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    # Inicializa sistema
    api_key = ANTHROPIC_API_KEY
    if not api_key:
        print(f"{GlifoLEF.VETO.value} AVISO: ANTHROPIC_API_KEY nÃ£o configurada")
        print("   Logos funcionarÃ¡ em modo mock (sem LLM real)")
        print("   Configure a variÃ¡vel de ambiente para LLM completo\n")

    sistema = AGIGaiaTechne(api_key=api_key, lat=LATITUDE, lon=LONGITUDE)

    # Menu interativo
    await sistema.menu_principal()

    # EstatÃ­sticas finais
    sistema.exibir_estatisticas()

    print(f"\n{GlifoLEF.GENESE.value} AtÃ© a prÃ³xima habitaÃ§Ã£o, Italo.\n")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print(f"\n\n{GlifoLEF.VETO.value} Sistema interrompido pelo operador")
    except Exception as e:
        print(f"\n{GlifoLEF.VETO.value} Erro fatal: {e}")
        import traceback
        traceback.print_exc()
